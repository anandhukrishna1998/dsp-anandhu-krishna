{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6964c2d8-cfc9-4e08-ac26-6ef0c0e62bd3",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5c59f5-9477-41be-b63b-2f593d2b19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab48c51-5fe6-4f40-9558-aa1659489142",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c20abd-d380-437f-9406-b5b5d6d432f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calucalting Root Mean Squared Logarithmic Error\n",
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)\n",
    "\n",
    "#function for calculating the other metrices\n",
    "def evaluate_performance(y_test, y_pred):\n",
    "    \n",
    "    rmsle_score = compute_rmsle(np.log(y_test), np.log(y_pred))\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    evaluation_results = {\n",
    "        \"rmsle_score\": rmsle_score,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R^2\": r2\n",
    "                }\n",
    "\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "def split_data(data: pd.DataFrame, target_column, test_size: float = 0.2, random_state: int = 42) -> tuple:\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns_to_drop = ['Alley', 'MasVnrType', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu', 'Id',\n",
    "                       'GarageYrBlt', '1stFlrSF', 'TotRmsAbvGrd', 'GarageArea']\n",
    "    data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "    return data\n",
    "    \n",
    "\n",
    "\n",
    "def fill_missing_values(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    return data\n",
    "    \n",
    "def feature_selection(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Performs feature selection based on correlation and chi-square test.\n",
    "    \"\"\"\n",
    "    features_dictionary = {}\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    numerical_correlations = train_data.select_dtypes(include=[np.number]).corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "    top_10_numerical_features = numerical_correlations[1:11].index.tolist()\n",
    "    \n",
    "    categorical_features = train_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    chi2_results = {feature: chi2_contingency(pd.crosstab(train_data[feature], train_data['SalePrice']))[0] for feature in categorical_features}\n",
    "    top_5_categorical_features = sorted(chi2_results, key=chi2_results.get, reverse=True)[:5]\n",
    "    \n",
    "\n",
    "    print('top_5_categorical_features is ',top_5_categorical_features)\n",
    "\n",
    "    file_path = '/home/sachin/DSP/dsp-anandhu-krishna/models/features_dictionary.json'\n",
    "\n",
    "    features_dictionary['top_10_numerical_features'] =top_10_numerical_features\n",
    "    features_dictionary['top_5_categorical_features'] =top_5_categorical_features\n",
    "\n",
    "    # Dumping the dictionary into a JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(features_dictionary, file)\n",
    "    \n",
    "    print(f\" features Dictionary saved to {file_path}\")\n",
    "    \n",
    "    return top_10_numerical_features, top_5_categorical_features\n",
    "\n",
    "def preprocess_features_train(X: pd.DataFrame, numeric_features: list, categorical_features: list, model_dir: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesses the given DataFrame by encoding categorical features and scaling numerical features.\n",
    "    \n",
    "    Args:\n",
    "    - X: DataFrame containing the training or test data.\n",
    "    - numeric_features: List of names of numeric features to scale.\n",
    "    - categorical_features: List of names of categorical features to encode.\n",
    "    - model_dir: Directory path where the preprocessing objects (encoder and scaler) will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - X_processed: A numpy array of processed features ready for training or prediction.\n",
    "    \"\"\"\n",
    "    # Initialize the encoder and scaler\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(X[categorical_features])\n",
    "    scaler = StandardScaler().fit(X[numeric_features])\n",
    "    \n",
    "    # Transform the data\n",
    "    X_encoded = encoder.transform(X[categorical_features]).toarray()\n",
    "    X_scaled = scaler.transform(X[numeric_features])\n",
    "    \n",
    "    # Combine encoded and scaled features\n",
    "    X_processed = np.hstack((X_scaled, X_encoded))\n",
    "    \n",
    "    # Save the preprocessing objects for later use\n",
    "    save_preprocessing_objects(encoder, scaler, model_dir)\n",
    "    \n",
    "    return X_processed\n",
    "    \n",
    "def preprocess_features_test(test_data: pd.DataFrame,top_10_numerical_features,top_5_categorical_features, model_dir: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesses the given DataFrame by encoding categorical features and scaling numerical features.\n",
    "    \n",
    "    Args:\n",
    "    - test_data: DataFrame containing the training or test data.\n",
    "    - model_dir: Directory path where the preprocessing objects (encoder and scaler) already saved.\n",
    "    \n",
    "    Returns:\n",
    "    - test_data_processed: A numpy array of processed features ready for training or prediction.\n",
    "    \"\"\"\n",
    "   # location of  the encoder and scaler objects\n",
    "    encoder_path = os.path.join(model_dir, 'encoder.joblib')\n",
    "    scaler_path = os.path.join(model_dir, 'scaler.joblib')\n",
    "    \n",
    "    # Load the encoder objects\n",
    "    loaded_encoder = joblib.load(encoder_path)\n",
    "    test_data_encoded = loaded_encoder.transform(test_data[top_5_categorical_features])\n",
    "    \n",
    "    \n",
    "    # Load the scaler objects\n",
    "    loaded_scaler = joblib.load(scaler_path)\n",
    "    test_data_scaled = loaded_scaler.transform(test_data[top_10_numerical_features])\n",
    "\n",
    "    # Combine scaled numeric features and encoded categorical features\n",
    "    test_data_processed = np.hstack((test_data_scaled, test_data_encoded.toarray()))\n",
    "\n",
    "    return test_data_processed\n",
    "\n",
    "\n",
    "def train_model(X_train: np.array, y_train: pd.Series, model_dir: str) -> XGBRegressor:\n",
    "    param = {\n",
    "        'max_depth': 4,            \n",
    "        'objective': 'reg:squarederror',  \n",
    "        'learning_rate': 0.1,   \n",
    "        'n_estimators': 200,       \n",
    "        'subsample': 0.7,          \n",
    "        'colsample_bytree': 0.8,    \n",
    "        'eval_metric': 'rmse'       \n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, os.path.join(model_dir, 'model.joblib'))\n",
    "    print(f'Model saved to {os.path.join(model_dir, \"model.joblib\")}')\n",
    "    \n",
    "def save_preprocessing_objects(encoder, scaler, model_dir: str) -> None:\n",
    "    joblib.dump(encoder, os.path.join(model_dir, 'encoder.joblib'))\n",
    "    joblib.dump(scaler, os.path.join(model_dir, 'scaler.joblib'))\n",
    "    print(f'Encoder and Scaler saved to {model_dir}')\n",
    "\n",
    "def load_features(file_path):\n",
    "    \"\"\"\n",
    "    Load the top 10 numerical features and top 5 categorical features from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two lists: top_10_numerical_features and top_5_categorical_features.\n",
    "    \"\"\"\n",
    "    # Loading the JSON data back into a Python dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        loaded_features_dictionary = json.load(file)\n",
    "    \n",
    "    # Extracting the features from the dictionary\n",
    "    top_10_numerical_features = loaded_features_dictionary['top_10_numerical_features']\n",
    "    top_5_categorical_features = loaded_features_dictionary['top_5_categorical_features']\n",
    "    \n",
    "    return top_10_numerical_features, top_5_categorical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c52275b-7cad-41be-916f-c23d7686b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X_train,y_train,model_dir) :\n",
    "    \n",
    "    X_train = clean_data(X_train) \n",
    "    X_train = fill_missing_values(X_train)\n",
    "    top_10_numerical_features, top_5_categorical_features = feature_selection(X_train,y_train)\n",
    "    X_train_processed  = preprocess_features_train(X_train,top_10_numerical_features,top_5_categorical_features,model_dir)\n",
    "    \n",
    "    train_model(X_train_processed, y_train ,model_dir)\n",
    "def model_evaluation(X_test,y_test,model_dir) :\n",
    "\n",
    "    X_test = clean_data(X_test) \n",
    "    X_test = fill_missing_values(X_test)\n",
    "    # Specify the file path from where you want to load the JSON\n",
    "    file_path = '/home/sachin/DSP/dsp-anandhu-krishna/models/features_dictionary.json'\n",
    "    top_10_numerical_features, top_5_categorical_features = load_features(file_path)\n",
    "    X_test_processed  = preprocess_features_test(X_test,top_10_numerical_features,top_5_categorical_features,model_dir)\n",
    "    model_path = os.path.join(model_dir, 'model.joblib')\n",
    "    #model loading\n",
    "    model = joblib.load(model_path)\n",
    "    #model predicitng\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    evaluation_results =evaluate_performance(y_test, y_pred)\n",
    "\n",
    "    return evaluation_results\n",
    "    \n",
    "def build_model(data: pd.DataFrame) -> dict[str, str]:\n",
    "\n",
    "    model_dir = '/home/sachin/DSP/dsp-anandhu-krishna/models'\n",
    "    X_train, X_test, y_train, y_test = split_data(data,\"SalePrice\")\n",
    "    \n",
    "    model_training(X_train,y_train,model_dir)\n",
    "\n",
    "    performances = model_evaluation(X_test,y_test,model_dir)\n",
    "\n",
    "    return performances\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134087e7-b1bc-4e91-9a47-2333dea88ec3",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14dd90ea-084b-46b8-a6da-4ffd5d6e59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_5_categorical_features is  ['Neighborhood', 'Exterior2nd', 'Exterior1st', 'SaleType', 'HouseStyle']\n",
      " features Dictionary saved to /home/sachin/DSP/dsp-anandhu-krishna/models/features_dictionary.json\n",
      "Encoder and Scaler saved to /home/sachin/DSP/dsp-anandhu-krishna/models\n",
      "Model saved to /home/sachin/DSP/dsp-anandhu-krishna/models/model.joblib\n",
      "the performances metrices are  {'rmsle_score': 0.01, 'MSE': 706354207.2513262, 'RMSE': 26577.32505823952, 'MAE': 17273.834853916953, 'R^2': 0.9079107995968321}\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/home/sachin/DSP/dsp-anandhu-krishna/data/train.csv')\n",
    "performances = build_model(train_data)\n",
    "print(\"the performances metrices are \" , performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc490e8-aec7-4758-9972-4703fb358702",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7e50d9-800b-48dd-bb21-75811e963e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_data: pd.DataFrame) -> np.ndarray:\n",
    "    #storing test_data_ids into a list\n",
    "    test_data_id= list(test_data['Id'])\n",
    "    model_dir = '/home/sachin/DSP/dsp-anandhu-krishna/models'\n",
    "    test_data_cleand = clean_data(test_data) \n",
    "    test_data_cleand = fill_missing_values(test_data_cleand)\n",
    "    # Specify the file path from where you want to load the JSON\n",
    "    file_path = '/home/sachin/DSP/dsp-anandhu-krishna/models/features_dictionary.json'\n",
    "    top_10_numerical_features, top_5_categorical_features = load_features(file_path)\n",
    "    test_data_processed  = preprocess_features_test(test_data_cleand,top_10_numerical_features,top_5_categorical_features,model_dir)\n",
    "    model_path = os.path.join(model_dir, 'model.joblib')\n",
    "    #model loading\n",
    "    model = joblib.load(model_path)\n",
    "    #model predicitng\n",
    "    test_data_pred = model.predict(test_data_processed)\n",
    "    #storing the predicted slaes price into a df\n",
    "    test_data_pred_df = pd.DataFrame(test_data_pred, columns=['pred_sales_price'])\n",
    "    #converting the Ids into a dataframe\n",
    "    test_data_id_df = pd.DataFrame(test_data_id, columns=['id'])\n",
    "    # Concatenate the new DataFrame with 'test_data_id_df' \n",
    "    df_combined = pd.concat([test_data_id_df, test_data_pred_df], axis=1)\n",
    "    \n",
    "    return df_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e409ca-85e5-4fcb-b285-9f29ab6a97a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred_sales_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>119319.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>142304.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181756.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>186675.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>201736.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>69565.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>82225.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>175976.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>115504.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>243123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  pred_sales_price\n",
       "0     1461     119319.164062\n",
       "1     1462     142304.906250\n",
       "2     1463     181756.421875\n",
       "3     1464     186675.765625\n",
       "4     1465     201736.968750\n",
       "...    ...               ...\n",
       "1454  2915      69565.773438\n",
       "1455  2916      82225.914062\n",
       "1456  2917     175976.859375\n",
       "1457  2918     115504.906250\n",
       "1458  2919     243123.000000\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('/home/sachin/DSP/dsp-anandhu-krishna/data/test.csv')\n",
    "\n",
    "\n",
    "test_data_pred = make_predictions(test_data)\n",
    "test_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00925a3c-29ae-4a05-951b-00bd25d6f6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc500493-7b8a-412b-9341-3699540f486c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
